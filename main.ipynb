{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_TRAIN_DIR = \"data/train_color\"\n",
    "BLACK_TRAIN_DIR = \"data/train_black\"\n",
    "COLOR_TEST_DIR = \"data/test_color\"\n",
    "BLACK_TEST_DIR = \"data/test_black2\"\n",
    "IMG_SIZE = 128 #images are 400x400 ---- Make them smaller to use less memory but keep accuracy\n",
    "BATCH_SIZE = 16 # hyperparameter we need to optimize\n",
    "EPOCHS = 5\n",
    "NUMBER_OF_IMAGES = 500\n",
    "DEVICE = torch.device(\"cpu\") #running on my macbook without a gpu ---- CAN ADD GPU SUPPPORT FOR OTHER DEVICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 is to create a class that can hold our loaded datasets, as well as process the images in our dataset for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizationDataset(Dataset):\n",
    "    # Built in double underscore python method to be the classe's constructor\n",
    "    def __init__(self, colorPaths, grayscalePaths, imageSize):\n",
    "        # This will define all images to class variables that are passed in the paths. i.e. \"data/train_color\" for self.colorpaths\n",
    "        self.colorPaths = sorted(glob(os.path.join(colorPaths, '*.jpg')))[:NUMBER_OF_IMAGES]\n",
    "        self.grayscalePaths = sorted(glob(os.path.join(grayscalePaths, '*.jpg')))[:NUMBER_OF_IMAGES]\n",
    "        self.imageSize = imageSize\n",
    "\n",
    "    # Built in double underscore python method to get length of data that our class instance holds\n",
    "    def __len__(self):\n",
    "        return len(self.grayscalePaths)\n",
    "\n",
    "    # Function to process grayscale training photos into L color space channel and return tensor\n",
    "    def processGrayscale(self, grayscaleImagePath):\n",
    "        # IMAGE GETS READ IN BGR COLOR SPACE\n",
    "        grayscaleImage = cv2.imread(grayscaleImagePath)\n",
    "        grayscaleImage = cv2.resize(grayscaleImage, (self.imageSize, self.imageSize))\n",
    "\n",
    "        # Defines LAB color space by using Opencv functions to take a colored image and put in into Lab\n",
    "        labColorSpace = cv2.cvtColor(grayscaleImage, cv2.COLOR_BGR2Lab)\n",
    "        \n",
    "        # Gets the chrominance of a and b channels by making all values within the range [-1,1] (Commonly used in neural networks)\n",
    "        L, a, b = cv2.split(labColorSpace)\n",
    "        # Since IMREAD_GRAYSCALE is already in L channel, we can just normalize grayscaleimage to be within -1 to 1\n",
    "        L = (L.astype(np.float32) - 128) / 128\n",
    "        L = torch.tensor(L, dtype=torch.float32).unsqueeze(0)\n",
    "        return L\n",
    "\n",
    "    # Function to process color training photos into a and b channels into a single stacked tensor\n",
    "    def processColor(self, colorImagePath):\n",
    "        # IMAGE GETS READ IN BGR COLOR SPACE\n",
    "        colorImage = cv2.imread(colorImagePath)\n",
    "        colorImage = cv2.resize(colorImage, (self.imageSize, self.imageSize))\n",
    "        \n",
    "        # Defines LAB color space by using Opencv functions to take a colored image and put in into Lab\n",
    "        labColorSpace = cv2.cvtColor(colorImage, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "        # Gets the chrominance of a and b channels by making all values within the range [-1,1] (Commonly used in neural networks)\n",
    "        L, a, b = cv2.split(labColorSpace)\n",
    "    \n",
    "        # Normalize a and b values to be within -1 to 1\n",
    "        L = (L.astype(np.float32) - 128) / 128\n",
    "        a = (a.astype(np.float32) - 128) / 128\n",
    "        b = (b.astype(np.float32) - 128) / 128\n",
    "        # Using stack to speed-up performance by joining a and b channels stacked on the 0 axis (All of a stacked on all of b)\n",
    "        lab = torch.tensor(np.stack([L,a,b], axis=0), dtype=torch.float32)\n",
    "\n",
    "        return lab\n",
    "\n",
    "    # Built in double underscore python method to get the index of the item in our class instance.\n",
    "    def __getitem__(self, idx):\n",
    "        grayscaleImagePath = self.grayscalePaths[idx]\n",
    "        colorImagePath = self.colorPaths[idx]\n",
    "        processedGrayscale = self.processGrayscale(grayscaleImagePath)\n",
    "        processedColor = self.processColor(colorImagePath)\n",
    "        return processedColor, processedGrayscale        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ColorizationModelNeuralNetwork(nn.Module):\n",
    "    # Class construction using same built in python double underscore method\n",
    "    def __init__(self):\n",
    "        super(ColorizationModelNeuralNetwork, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(64),  # Add BatchNorm\n",
    "            nn.ReLU(), # USING THE RELU ACTIVATION FUNCTION LIKE WE SAW IN CLASS\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(128),  # Add BatchNorm\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(256),  # Add BatchNorm\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(128),  # Add BatchNorm\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(64),  # Add BatchNorm\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=(3,3), padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will put our images into a class dataset so we can load and process the images before training the model\n",
    "train_dataset = ColorizationDataset(COLOR_TRAIN_DIR, BLACK_TRAIN_DIR, IMG_SIZE)\n",
    "test_dataset = ColorizationDataset(COLOR_TEST_DIR, BLACK_TEST_DIR, IMG_SIZE)\n",
    "\n",
    "# Loads the data correctly in a certain batch size to help with the EPOCH's in our training process.\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we want to initialize the model, the mean squared error loss criterion, and the optimizer for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorizerModel = ColorizationModelNeuralNetwork().to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(colorizerModel.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Load Our Image Dataset we chose and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.0396\n",
      "Epoch 2/5, Loss: 0.0162\n",
      "Epoch 3/5, Loss: 0.0135\n",
      "Epoch 4/5, Loss: 0.0128\n",
      "Epoch 5/5, Loss: 0.0122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists for epoch and loss tracking\n",
    "epoch_losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    colorizerModel.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for color_lab_space, grayScale_L_channel in train_loader:\n",
    "        color_lab_space, grayScale_L_channel = color_lab_space.to(DEVICE), grayScale_L_channel.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        grayscale_lab_prediction = colorizerModel(grayScale_L_channel)\n",
    "\n",
    "        loss = criterion(grayscale_lab_prediction, color_lab_space)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)  # Average loss for this epoch\n",
    "    epoch_losses.append(avg_loss)  # Store loss for plotting\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Plot after training\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, EPOCHS + 1), epoch_losses, marker='o', label=\"Average Loss per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400, 400])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400, 400])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def colorizeImage(model, imagePath):\n",
    "    # IMAGE GETS READ IN BGR COLOR SPACE\n",
    "    grayscaleTestImage = cv2.imread(imagePath)\n",
    "    labColorSpaceImage = labColorSpace = cv2.cvtColor(grayscaleTestImage, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "    L_space, a, b = cv2.split(labColorSpaceImage)\n",
    "    L_space = (L_space.astype(np.float32) - 128) / 128\n",
    "    L_space_tensor = torch.tensor(L_space, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    L_space_tensor = L_space_tensor.to(DEVICE)\n",
    "    print(L_space_tensor.shape)\n",
    "    with torch.no_grad():\n",
    "        lab_prediction = model(L_space_tensor).cpu()\n",
    "\n",
    "    lab_prediction = lab_prediction.squeeze().numpy()\n",
    "    # Un-regularizes the values that were between [-1,1]\n",
    "    l = lab_prediction[0].astype(np.float32) * 128 + 128\n",
    "    a = lab_prediction[1].astype(np.float32) * 128 + 128\n",
    "    b = lab_prediction[2].astype(np.float32) * 128 + 128\n",
    "    \n",
    "    #L = ((L_image * 128) + 128) \n",
    "    \n",
    "    # uint8 is so that the values will be 2^8 bit so range will be within rgb values\n",
    "    colorized_lab = cv2.merge([l.astype(np.uint8), a.astype(np.uint8), b.astype(np.uint8)])\n",
    "\n",
    "    colorized_rgb = cv2.cvtColor(colorized_lab, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    plt.imshow(colorized_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def colorizeTestSet(model, imageSetPath):\n",
    "    for image in os.listdir(imageSetPath):\n",
    "        if image.endswith('.jpg'):\n",
    "            grayscalePath = os.path.join(imageSetPath, image)\n",
    "            colorizeImage(model, grayscalePath)\n",
    "\n",
    "colorizeTestSet(colorizerModel, BLACK_TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
