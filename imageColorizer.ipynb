{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference for this code:\n",
    "After attempting multiple different network models, we were finally able to find some major online help to apply our dataset on a new model that ended up working. The code below still uses OpenCV but adds PIL image to read and process all images. It then applies a General Adversarial Network (GAN) with a UNet Network as the generator, and a discriminator network to combine the predicted channels from the UNet network and determine if the image is real or fake based-upon labels given.\n",
    "\n",
    "Majority of this model and the methods/code used were found in the Towards Data Science. There are still some aspects of the code that we tried to preserve from our previous iterations of work such as using OpenCV, batch normalization, ReLU, and the overall approach of a CNN. The full citation and retrieval information can be found in the citation below.\n",
    "\n",
    "Shariatnia, M (2020, November 18). Colorizing black and white images with U-Net and conditional GAN: A tutorial. Towards Data Science. Retrieved December 3, 2024, from https://towardsdatascience.com/colorizing-black-white-images-with-u-net-and-conditional-gan-a-tutorial-81b2df111cd8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Data Paths, Grabbing Images to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500 3 500\n"
     ]
    }
   ],
   "source": [
    "COLOR_TRAIN_DIR = \"data/train_color\"\n",
    "BLACK_TRAIN_DIR = \"data/train_black\"\n",
    "COLOR_TEST_DIR = \"data/test_color2\"\n",
    "BLACK_TEST_DIR = \"data/test_black2\"\n",
    "IMG_SIZE = 256 #images are 400x400 ---- Make them smaller to use less memory but keep accuracy\n",
    "BATCH_SIZE = 32 # hyperparameter we need to optimize - 16 working fine for now\n",
    "EPOCHS = 100\n",
    "NUMBER_OF_IMAGES = 5000\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trainPaths = glob(COLOR_TRAIN_DIR + \"/*.jpg\")\n",
    "testPaths = glob(COLOR_TEST_DIR + \"/*.jpg\")\n",
    "\n",
    "trainPaths = np.random.choice(trainPaths, NUMBER_OF_IMAGES, replace=False) # chooses images in random order\n",
    "trainPaths, valPaths = train_test_split(trainPaths, test_size=0.1, random_state=42)\n",
    "\n",
    "print(len(trainPaths), len(testPaths), len(valPaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, paths, split='train'):\n",
    "        if split == 'train':\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "                transforms.RandomHorizontalFlip(), # Add in data augmentation if it is in training mode\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        elif split == 'val' or split == 'test':\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        \n",
    "        self.split = split\n",
    "        self.size = IMG_SIZE\n",
    "        self.paths = paths\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Use OpenCV to read images\n",
    "        img = cv2.imread(self.paths[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Apply transforms depending on the mode, need to also conver to PIL image here\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img).numpy().transpose(1, 2, 0)\n",
    "        \n",
    "        # Convert rgb into lab\n",
    "        labImage = cv2.cvtColor(img, cv2.COLOR_RGB2Lab)\n",
    "        \n",
    "        # Normalize all lab channels between -1 and 1\n",
    "        L = labImage[:,:,0] / 50. - 1.\n",
    "        ab = labImage[:,:,1:] / 110.\n",
    "        \n",
    "        # Convert to tensors before returning\n",
    "        L = torch.from_numpy(L).unsqueeze(0)\n",
    "        ab = torch.from_numpy(ab).permute(2, 0, 1)\n",
    "        \n",
    "        return {'L': L, 'ab': ab}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(batch_size=BATCH_SIZE, pin_memory=True, **kwargs):\n",
    "    dataset = ColorizationDataset(**kwargs)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, pin_memory=pin_memory)\n",
    "    return dataloader\n",
    "\n",
    "loadedTraining = loadData(paths=trainPaths, split='train')\n",
    "loadedVal = loadData(paths=valPaths, split='val')\n",
    "loadedTest = loadData(paths=testPaths, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unet_model.png'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, num_output_filters, num_input_filters, submodule=None, input_channels=None, dropout=False,\n",
    "                 innermost=False, outermost=False):\n",
    "        super().__init__()\n",
    "        self.outermost = outermost\n",
    "        if input_channels is None: input_channels = num_output_filters\n",
    "        downconv = nn.Conv2d(input_channels, num_input_filters, kernel_size=4,\n",
    "                             stride=2, padding=1, bias=False)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = nn.BatchNorm2d(num_input_filters)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = nn.BatchNorm2d(num_output_filters)\n",
    "        \n",
    "        if outermost:\n",
    "            upconv = nn.ConvTranspose2d(num_input_filters * 2, num_output_filters, kernel_size=4,\n",
    "                                        stride=2, padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(num_input_filters, num_output_filters, kernel_size=4,\n",
    "                                        stride=2, padding=1, bias=False)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(num_input_filters * 2, num_output_filters, kernel_size=4,\n",
    "                                        stride=2, padding=1, bias=False)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            if dropout: up += [nn.Dropout(0.5)]\n",
    "            model = down + [submodule] + up\n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            return torch.cat([x, self.model(x)], 1)\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n",
    "        super().__init__()\n",
    "        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n",
    "        for _ in range(n_down - 5):\n",
    "            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n",
    "        out_filters = num_filters * 8\n",
    "        for _ in range(3):\n",
    "            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n",
    "            out_filters //= 2\n",
    "        self.model = UnetBlock(output_c, out_filters, input_channels=input_c, submodule=unet_block, outermost=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, input_channels, num_filters=64, n_down=3):\n",
    "        super().__init__()\n",
    "        model = [self.get_layers(input_channels, num_filters, norm=False)]\n",
    "        # the 'if' statement is taking care of not using stride of 2 for the last block in this loop so dimension size isn't altered\n",
    "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) for i in range(n_down)] \n",
    "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] # Make sure to not use normalization or activation here\n",
    "        self.model = nn.Sequential(*model)                                                   \n",
    "        \n",
    "    # Function to get repetitive blocks of layers\n",
    "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): \n",
    "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]\n",
    "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
    "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, real_label=1.0, fake_label=0.0):\n",
    "        super().__init__()\n",
    "        # Makes tensor of either 0's or 1's depending on real or fake label\n",
    "        self.register_buffer('real_label', torch.tensor(real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
    "        # Uses Binary Cross Entropy Loss since we are dealing with binary classiication for real or fake images\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def get_labels(self, preds, target_is_real):\n",
    "        if target_is_real:\n",
    "            labels = self.real_label\n",
    "        else:\n",
    "            labels = self.fake_label\n",
    "        return labels.expand_as(preds)\n",
    "    \n",
    "    def __call__(self, preds, target_is_real):\n",
    "        labels = self.get_labels(preds, target_is_real)\n",
    "        loss = self.loss(preds, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize weights of model with mean of 0.0 and standard deviation of 0.02 which are hyperparam values\n",
    "def init_weights(net, gain=0.02):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
    "            nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif 'BatchNorm2d' in classname:\n",
    "            nn.init.normal_(m.weight.data, 1., gain)\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "            \n",
    "    net.apply(init_func)\n",
    "    return net\n",
    "\n",
    "def init_model(model, device):\n",
    "    model = model.to(device)\n",
    "    model = init_weights(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainModel(nn.Module):\n",
    "    def __init__(self, lr_G=2e-4, lr_D=2e-4, \n",
    "                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n",
    "        super().__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.lambda_L1 = lambda_L1\n",
    "        self.genNetwork = init_model(Unet(input_c=1, output_c=2, n_down=8, num_filters=64), self.device)\n",
    "        self.discrimNetwork = init_model(PatchDiscriminator(input_channels=3, n_down=3, num_filters=64), self.device)\n",
    "        self.GANcriterion = GANLoss().to(self.device)\n",
    "        self.L1criterion = nn.L1Loss()\n",
    "        self.opt_G = optim.Adam(self.genNetwork.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "        self.opt_D = optim.Adam(self.discrimNetwork.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "    \n",
    "    def set_requires_grad(self, model, requires_grad=True):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "        \n",
    "    def setup_input(self, data):\n",
    "        self.L = data['L'].to(self.device)\n",
    "        self.ab = data['ab'].to(self.device)\n",
    "        \n",
    "    def forward(self):\n",
    "        self.fake_color = self.genNetwork(self.L)\n",
    "        \n",
    "    def backward_D(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.discrimNetwork(fake_image.detach())\n",
    "        self.loss_Discriminator_fake = self.GANcriterion(fake_preds, False)\n",
    "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
    "        real_preds = self.discrimNetwork(real_image)\n",
    "        self.loss_Discriminator_real = self.GANcriterion(real_preds, True)\n",
    "        self.loss_Discriminator = (self.loss_Discriminator_fake + self.loss_Discriminator_real) * 0.5\n",
    "        self.loss_Discriminator.backward()\n",
    "    \n",
    "    def backward_G(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.discrimNetwork(fake_image)\n",
    "        self.loss_Generator_GAN = self.GANcriterion(fake_preds, True)\n",
    "        self.loss_Generator_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
    "        self.loss_Generator = self.loss_Generator_GAN + self.loss_Generator_L1\n",
    "        self.loss_Generator.backward()\n",
    "    \n",
    "    def optimize(self):\n",
    "        # Forward pass and stores fake_color images\n",
    "        self.forward()\n",
    "        # Trains discrim network and performs gradient descent on network\n",
    "        self.discrimNetwork.train()\n",
    "        self.set_requires_grad(self.discrimNetwork, True)\n",
    "        self.opt_D.zero_grad()\n",
    "        # Feeds fake images and labels them as fake, then feeds real images and calculates loss\n",
    "        self.backward_D()\n",
    "        self.opt_D.step()\n",
    "        \n",
    "        # Now train generator -> feed fake images and label them as real to see if model can learn that it is actually fake\n",
    "        self.genNetwork.train()\n",
    "        self.set_requires_grad(self.discrimNetwork, False)\n",
    "        self.opt_G.zero_grad()\n",
    "        # Uses L1 loss to compute distance between channels for the backward step of generator\n",
    "        self.backward_G()\n",
    "        self.opt_G.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to update and reset averages, sum, and counts for losses\n",
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.count, self.avg, self.sum = [0.] * 3\n",
    "    \n",
    "    def update(self, val, count=1):\n",
    "        self.count += count\n",
    "        self.sum += count * val\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "# Functions for creating and updating all loss values\n",
    "def create_loss_meters():\n",
    "    loss_Discriminator_fake = AverageMeter()\n",
    "    loss_Discriminator_real = AverageMeter()\n",
    "    loss_Discriminator = AverageMeter()\n",
    "    loss_Generator_GAN = AverageMeter()\n",
    "    loss_Generator_L1 = AverageMeter()\n",
    "    loss_Generator = AverageMeter()\n",
    "    \n",
    "    return {'loss_Discriminator_fake': loss_Discriminator_fake,\n",
    "            'loss_Discriminator_real': loss_Discriminator_real,\n",
    "            'loss_Discriminator': loss_Discriminator,\n",
    "            'loss_Generator_GAN': loss_Generator_GAN,\n",
    "            'loss_Generator_L1': loss_Generator_L1,\n",
    "            'loss_Generator': loss_Generator}\n",
    "\n",
    "def update_losses(model, loss_meter_dict, count):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        loss = getattr(model, loss_name)\n",
    "        loss_meter.update(loss.item(), count=count)\n",
    "\n",
    "# Converts lab to rgb and concatenates a single image\n",
    "def lab_to_rgb(L, ab):\n",
    "    L = (L + 1.) * 50.\n",
    "    ab = ab * 110.\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "    rgb_imgs = []\n",
    "    for img in Lab:\n",
    "        img_rgb = lab2rgb(img)\n",
    "        rgb_imgs.append(img_rgb)\n",
    "    return np.stack(rgb_imgs, axis=0)\n",
    "\n",
    "def log_results(loss_meter_dict):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        print(f\"{loss_name}: {loss_meter.avg:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from article \n",
    "def train_model(model, trainDataLoder, epochs, savedModelPath, display_every=100):\n",
    "    data = next(iter(loadedVal)) # Going to test the model while training using the test set and predicted output to update our losses\n",
    "    for e in range(epochs):\n",
    "        loss_meter_dict = create_loss_meters() # function returing a dictionary of objects to log the losses of the complete network\n",
    "        i = 0\n",
    "        for data in tqdm(trainDataLoder):\n",
    "            model.setup_input(data) \n",
    "            model.optimize() # Calls optimize function in MainModel to perform all training for each batch\n",
    "            update_losses(model, loss_meter_dict, count=data['L'].size(0)) # function updating the log objects\n",
    "            i += 1\n",
    "            # Display all updated loss values every so often throughout each epoch\n",
    "            if i % display_every == 0:\n",
    "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
    "                print(f\"Iteration {i}/{len(trainDataLoder)}\")\n",
    "                log_results(loss_meter_dict) # function to print out the losses\n",
    "\n",
    "    # Save the model at the very end to use for testing on unseen images using the already implemented visualize function\n",
    "    torch.save(model.state_dict(), savedModelPath)\n",
    "\n",
    "# Initialize the model, setup a saved path, and then train the model\n",
    "model = MainModel()\n",
    "savedModelPath = 'trained_model.pth'\n",
    "train_model(model, loadedTraining, EPOCHS, savedModelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the model and visualize all UNSEEN test images to see how the model performs \n",
    "def test_model(model, testDataLoader, modelPath, save=False):\n",
    "    for data in testDataLoader:\n",
    "        # Using code provided for visualizing and testing the network from article\n",
    "        model.load_state_dict(torch.load(modelPath))\n",
    "        model.genNetwork.eval()\n",
    "        with torch.no_grad():\n",
    "            model.setup_input(data)\n",
    "            model.forward()\n",
    "        model.genNetwork.train()\n",
    "\n",
    "        # Gets predicted and real image channels\n",
    "        predictedImage = model.fake_color.detach()\n",
    "        realImage = model.ab\n",
    "        L = model.L\n",
    "\n",
    "        # Concatenates all channels to make a final rgb image for both real and predicted\n",
    "        predictedImages = lab_to_rgb(L, predictedImage)\n",
    "        realImages = lab_to_rgb(L, realImage)\n",
    "\n",
    "        # Create a figure\n",
    "        fig, axes = plt.subplots(3, len(data) + 1, figsize=(15, 10))  # Create a 3x3 grid\n",
    "        \n",
    "        # Loops through rows and columns in each row to output all test images on model\n",
    "        for row in range(len(data) + 1):\n",
    "            # Grayscale image\n",
    "            axes[row, 0].imshow(L[row][0].cpu(), cmap='gray')\n",
    "            axes[row, 0].set_title(f\"Grayscale {row + 1}\")\n",
    "            axes[row, 0].axis(\"off\")\n",
    "            # Predicted image\n",
    "            axes[row, 1].imshow(predictedImages[row])\n",
    "            axes[row, 1].set_title(f\"Predicted {row + 1}\")\n",
    "            axes[row, 1].axis(\"off\")\n",
    "            # Real image\n",
    "            axes[row, 2].imshow(realImages[row]) \n",
    "            axes[row, 2].set_title(f\"Real {row + 1}\")\n",
    "            axes[row, 2].axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # For if we want to save the plot figure\n",
    "        if save:\n",
    "            fig.savefig(f\"colorization_{time.time()}.png\")\n",
    "        \n",
    "\n",
    "test_model(model, loadedTest, savedModelPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
